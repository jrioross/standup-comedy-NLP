{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f003b34",
   "metadata": {},
   "source": [
    "# Feature Engineering: Point of View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d137a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a910447",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a2a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4371258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/metascripts_repetition_df', 'rb') as file:\n",
    "    metascripts = pickle.load(file)\n",
    "    \n",
    "with open('../data/pos_props_df.pickle', 'rb') as file:\n",
    "    pos_df = pickle.load(file)\n",
    "    \n",
    "with open('../data/docs_pos_counts_words_dict.pickle', 'rb') as file:\n",
    "    docs_pos_counts_words = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee76b54",
   "metadata": {},
   "source": [
    "## prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479df105",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = list(metascripts['description'].values())\n",
    "scripts = list(metascripts['transcript'].values())\n",
    "scripts_dict = zip(descriptions, scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize scripts to words\n",
    "tok_scripts = [regexp_tokenize(script, r\"\\b[a-zA-Z'\\w\\-\\*]+\\b\") for script in scripts]\n",
    "\n",
    "# lower case all words\n",
    "tok_scripts_lc = [[token.lower() for token in script] for script in tok_scripts]\n",
    "\n",
    "# return dictionary of counts of words for each show\n",
    "word_counts = [Counter(token for token in script) for script in tok_scripts_lc]\n",
    "\n",
    "# make a gensim corpus\n",
    "dictionary = Dictionary(tok_scripts_lc)\n",
    "corpus = [dictionary.doc2bow(script) for script in tok_scripts_lc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f04551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# designate point-of-view pronouns\n",
    "first_pron = [\"i\", \"me\", \"my\", \"mine\", \"myself\",\n",
    "            \"we\", \"us\", \"our\", \"ours\", \"ourselves\"]\n",
    "\n",
    "second_pron = [\"you\", \"your\", \"yours\"]\n",
    "\n",
    "third_pron = [\"he\", \"she\", \"it\",\n",
    "            \"him\", \"her\",\n",
    "            \"his\", \"its\", \"hers\",\n",
    "            \"they\", \"them\", \"their\", \"theirs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ab7c1",
   "metadata": {},
   "source": [
    "## point-of-view frequencies and proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pov(word_dict, pos_dict):\n",
    "    \"\"\"\n",
    "    Count pronoun usage using pronoun labels and spaCy part-of-speech assignments.\n",
    "    Nouns and proper nouns are counted as third person along with the usual 3rd-person pronouns.\n",
    "    \"\"\"\n",
    "    pov_dict = defaultdict(int)\n",
    "    for word, count in word_dict.items():\n",
    "        if word in first_pron:\n",
    "            pov_dict['first_person'] += count\n",
    "        elif word in second_pron:\n",
    "            pov_dict['second_person'] += count\n",
    "        elif word in third_pron:\n",
    "            pov_dict['third_person'] += count\n",
    "    pov_dict['third_person'] += pos_dict['NOUN'] + pos_dict['PROPN']\n",
    "    return dict(pov_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a readable and searchable wordcount dictionary of dictionaries\n",
    "word_counts_dicts = [{dictionary[entry[0]]: entry[1] for entry in index_counts} for index_counts in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56325901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pov counts list of dictionaries using the function defined above.\n",
    "pov_counts = [count_pov(word_count_dict, pos_count_dict) for word_count_dict, pos_count_dict in zip(word_counts_dicts, docs_pos_counts_words)]\n",
    "\n",
    "# get proportion of each type of pronoun compared to all words (hence \"overall\")\n",
    "pov_props_overall = [{pov: count/sum(word_count_dict.values()) for pov, count in pov_count_dict.items()} for pov_count_dict, word_count_dict in zip(pov_counts, word_counts_dicts)]\n",
    "\n",
    "# get proportion of each type of pronoun compared to other pronouns\n",
    "pov_props_relative = [{pov: count/sum(pov_count_dict.values()) for pov, count in pov_count_dict.items()} for pov_count_dict in pov_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes from each list of dictionaries created above\n",
    "def make_pov_df(pov_dict):\n",
    "    return pd.DataFrame.from_dict(dict(zip(descriptions, pov_dict)), orient = 'index').reset_index().rename(columns = {'index':'description'})\n",
    "\n",
    "pov_counts_df = make_pov_df(pov_counts)\n",
    "pov_props_overall_df = make_pov_df(pov_props_overall)\n",
    "pov_props_relative_df = make_pov_df(pov_props_relative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aeb64e",
   "metadata": {},
   "source": [
    "## pickle point-of-view dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce62bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pov_counts_df.pickle', 'wb') as file:\n",
    "    pickle.dump(pov_counts_df, file)\n",
    "    \n",
    "with open('../data/pov_props_overall_df.pickle', 'wb') as file:\n",
    "    pickle.dump(pov_props_overall_df, file)\n",
    "    \n",
    "with open('../data/pov_props_relative_df.pickle', 'wb') as file:\n",
    "    pickle.dump(pov_props_relative_df, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

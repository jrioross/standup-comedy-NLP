{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb271cf3",
   "metadata": {},
   "source": [
    "# Feature Engineering: Parts of Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81636f46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59947e9e",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import Phrases\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e578ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c8841",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/metascripts_df_profanity', 'rb') as file:\n",
    "    metascripts = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd461d80",
   "metadata": {},
   "source": [
    "## prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = list(metascripts['description'].values())\n",
    "scripts = list(metascripts['transcript'].values())\n",
    "scripts_dict = zip(descriptions, scripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f38c3",
   "metadata": {},
   "source": [
    "## part-of-speech frequencies and proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chunker to manage memory usage\n",
    "def chunker(iterable, chunksize):\n",
    "    for i in range(0, len(list(iterable)), chunksize):\n",
    "        yield iterable[i:i+chunksize]\n",
    "\n",
    "# create function that builds a dictionary from pos counts\n",
    "def get_doc_pos_count(doc):\n",
    "    pos_dict = {}\n",
    "    for token in doc:\n",
    "        if token.pos_ in pos_dict.keys():\n",
    "            pos_dict[token.pos_] += 1\n",
    "        else:\n",
    "            pos_dict[token.pos_] = 1\n",
    "    return pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the English model: nlp\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# stream scripts in chunks through the nlp pipe, make pos counts dictionaries, and append to complete list\n",
    "docs_pos_counts = []\n",
    "for scripts_subset in tqdm(chunker(scripts, 10), total = np.ceil(len(scripts)/10)):\n",
    "    subset_list = [get_doc_pos_count(doc) for doc in nlp.pipe(scripts_subset)]\n",
    "    docs_pos_counts.extend(subset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn list of dictionary counts to dictionary of dictionary counts of only actual words\n",
    "docs_pos_counts_words = [{pos: count for pos, count in count_dict.items() if pos not in ['PUNCT', 'SPACE', 'X']} for count_dict in docs_pos_counts]\n",
    "show_pos_counts = dict(zip(descriptions, docs_pos_counts_words))\n",
    "\n",
    "# create dictionary of dictionaries of pos proportions by show\n",
    "show_pos_props = {description: {pos: count/sum(counts_dict.values()) for pos, count in counts_dict.items()} for description, counts_dict in show_pos_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e28e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pos proportion dataframe, pos_df\n",
    "pos_df = (pd.DataFrame.from_dict(show_pos_props, orient = 'index')\n",
    "                      .fillna(0)\n",
    "                      .reset_index()\n",
    "                      .rename(columns = {'index':'description'})\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df9848",
   "metadata": {},
   "source": [
    "## pickle pos_df and docs_pos_counts_words for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9282575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle pos_df for future use\n",
    "with open('../data/pos_props_df.pickle', 'wb') as file:\n",
    "    pickle.dump(pos_df, file)\n",
    "    \n",
    "with open('../data/docs_pos_counts_words_dict.pickle', 'wb') as file:\n",
    "    pickle.dump(pos_df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caad2076",
   "metadata": {},
   "source": [
    "## explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_col = 'VERB'\n",
    "px.box(pos_df, x = pos_col, hover_data = ['description'], points = 'all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b8b279",
   "metadata": {},
   "source": [
    "# Feature Engineering: Profanity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49dcb54",
   "metadata": {},
   "source": [
    "There are several options for detecting profanity. Three prominent ones are\n",
    "\n",
    "   - [x] [profanity-filter](#https://pypi.org/project/profanity-filter/): a sophisticated, word-list-based package with boolean methods like is_profane\n",
    "   - [ ] [profanity-check](#https://pypi.org/project/alt-profanity-check/): a model-based approach to profanity detection compatible with spaCy\n",
    "   - [ ] [better-profanity](#https://pypi.org/project/better-profanity/): another list-based approach, though less accurate than profanity-filter\n",
    "   \n",
    "profanity-filter is the most appropriate for this project. While a model-based approach is appealing, it's more likely to identify words or sentences as profane because the sentence has the structure of an insult. For instance, if a comedian says, \"That guy is a dingleberry,\" profanity-check would flag it as profane, while profanity-filter would not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a976b",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693965da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import Phrases\n",
    "\n",
    "from profanityfilter import ProfanityFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/metascripts/metascript_df_ws.pickle', 'rb') as file:\n",
    "    metascripts = pickle.load(metascripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6e3af",
   "metadata": {},
   "source": [
    "## prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60aab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = list(metascripts['description'].values())\n",
    "scripts = list(metascripts['transcript'].values())\n",
    "scripts_dict = zip(descriptions, scripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9dbb3",
   "metadata": {},
   "source": [
    "## profanity detection, frequency, and proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1796ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = ProfanityFilter()\n",
    "tok_scripts = [regexp_tokenize(transcript, r\"\\b[a-zA-Z'\\w\\-\\*]+\\b\") for transcript in scripts]\n",
    "tok_scripts_lc = [[token.lower() for token in script] for script in tok_scripts]\n",
    "word_counts = [Counter(token for token in script) for script in tok_scripts_lc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dce738",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(tok_scripts_lc)\n",
    "corpus = [dictionary.doc2bow(script) for script in tok_scripts_lc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e074ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_overall_counts = {}\n",
    "for bow in tqdm(corpus):\n",
    "    for id, count in bow:\n",
    "        if dictionary[id] in corpus_overall_counts.keys():\n",
    "            corpus_overall_counts[dictionary[id]] += count\n",
    "        else:\n",
    "            corpus_overall_counts[dictionary[id]] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "profane_dict = {word: pf.is_profane(word) for word in tqdm(corpus_overall_counts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/profanity_booleans_no_lemma.pickle', 'wb') as file:\n",
    "    pickle.dump(profane_dict, file)\n",
    "    \n",
    "with open('../data/profanity_booleans_no_lemma.pickle', 'rb') as file:\n",
    "    profane_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profanity_counts = {description: {word:count for word, count in script_counts.items() if profane_dict[word]} for script_counts, description in zip(word_counts,descriptions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "profane_words = [sum(words.values()) for description, words in profanity_counts.items()]\n",
    "total_words = [sum(script_word_counts.values()) for script_word_counts in word_counts]\n",
    "profane_proportion = [profane/total for profane, total in zip(profane_words, total_words)]\n",
    "profane_per_sent = [profane/sent_count for profane, sent_count in zip(profane_words, sent_counts)]\n",
    "profane_per_min = [profane/minutes for profane, minutes in zip(profane_words, metascripts['runtimeMins'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b9886",
   "metadata": {},
   "outputs": [],
   "source": [
    "metascripts['profane count'] = profane_words\n",
    "metascripts['profane proportion'] = profane_proportion\n",
    "metascripts['profanity per sentence'] = profane_per_sent\n",
    "metascripts['profanity per minute'] = profane_per_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63a78d",
   "metadata": {},
   "source": [
    "## pickle updated metascripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/metascripts_df_profanity.pickle', 'wb') as file:\n",
    "    pickle.dump(metascripts, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f45214",
   "metadata": {},
   "source": [
    "## explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11abbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(metascripts, x = 'profanity per minute', hover_data = ['description', 'profane count'], points = 'all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
